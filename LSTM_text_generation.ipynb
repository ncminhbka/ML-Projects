{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN3c3OSQdKosdSrT4qycrRr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ncminhbka/ML-Projects/blob/main/LSTM_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nh·ªõ r·∫±ng LSTM ho·∫°t ƒë·ªông kh√¥ng ph·ª• thu·ªôc seqlen, c√≥ bao nhi√™u n√≥ t·∫°o b·∫•y nhi√™u cell v√† √°p d·ª•ng c√πng b·ªô tr·ªçng s·ªë. Khi train do batch c·ªë ƒë·ªãnh k√≠ch th∆∞·ªõc n√™n ta ph·∫£i ch·ªçn seqlen c·ªë ƒë·ªãnh, nh∆∞ng khi infer input c·ªßa ta d√†i bao nhi√™u c≈©ng ƒë∆∞·ª£c. N·∫øu b·∫°n th√≠ch th√¨ b·ªè batch ƒëi, train t·ª´ng sample m·ªôt th√¨ seqlen s·∫Ω ƒë∆∞·ª£c t√πy √Ω (haha)"
      ],
      "metadata": {
        "id": "QbJIePpHKv8i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XweudnNvqTt8",
        "outputId": "5d6745e8-605c-46e6-b3d4-67968a9a0fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-12 15:03:43--  https://www.gutenberg.org/cache/epub/1513/pg1513.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169546 (166K) [text/plain]\n",
            "Saving to: ‚Äòshakespeare.txt‚Äô\n",
            "\n",
            "shakespeare.txt     100%[===================>] 165.57K   624KB/s    in 0.3s    \n",
            "\n",
            "2025-10-12 15:03:44 (624 KB/s) - ‚Äòshakespeare.txt‚Äô saved [169546/169546]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O shakespeare.txt https://www.gutenberg.org/cache/epub/1513/pg1513.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tr∆∞·ªõc khi ch·∫°y c·∫ßn v√†o shakespeare.txt x√≥a c√°c d√≤ng kh√¥ng li√™n quan (·ªü ƒë·∫ßu v√† cu·ªëi)"
      ],
      "metadata": {
        "id": "9fbsXWcE0loz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "ILH15ZvPsx3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'shakespeare.txt'\n",
        "with open(filename, 'r', encoding = 'utf-8') as f:\n",
        "    raw_text = f.read()\n",
        "raw_text = raw_text.lower()\n",
        "\n",
        "import re\n",
        "\n",
        "# Lo·∫°i b·ªè c√°c d√≤ng to√†n ch·ªØ in hoa (th∆∞·ªùng l√† ti√™u ƒë·ªÅ, nh√¢n v·∫≠t, t√™n c·∫£nh)\n",
        "clean_text = []\n",
        "for line in raw_text.splitlines():\n",
        "    line = line.strip()\n",
        "    # B·ªè d√≤ng r·ªóng ho·∫∑c d√≤ng to√†n ch·ªØ in hoa (SCENE I, ROMEO, CAPULET, v.v.)\n",
        "    if not line or line.isupper():\n",
        "        continue\n",
        "    clean_text.append(line)\n",
        "\n",
        "# G·ªôp l·∫°i th√†nh m·ªôt chu·ªói duy nh·∫•t\n",
        "raw_text = \" \".join(clean_text)\n",
        "\n",
        "\n",
        "\n",
        "print(raw_text[:1000])\n",
        "\n",
        "\n",
        "\n",
        "#charecter-level\n",
        "vocab = sorted(list(set(raw_text)))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(vocab)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "QJMJg_J8qk-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f59820b-3ff9-4312-e2df-1d2d9c0ab524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the tragedy of romeo and juliet by william shakespeare contents the prologue. act i scene i. a public place. scene ii. a street. scene iii. room in capulet‚Äôs house. scene iv. a street. scene v. a hall in capulet‚Äôs house. act ii chorus. scene i. an open place adjoining capulet‚Äôs garden. scene ii. capulet‚Äôs garden. scene iii. friar lawrence‚Äôs cell. scene iv. a street. scene v. capulet‚Äôs garden. scene vi. friar lawrence‚Äôs cell. act iii scene i. a public place. scene ii. a room in capulet‚Äôs house. scene iii. friar lawrence‚Äôs cell. scene iv. a room in capulet‚Äôs house. scene v. an open gallery to juliet‚Äôs chamber, overlooking the garden. act iv scene i. friar lawrence‚Äôs cell. scene ii. hall in capulet‚Äôs house. scene iii. juliet‚Äôs chamber. scene iv. hall in capulet‚Äôs house. scene v. juliet‚Äôs chamber; juliet on the bed. act v scene i. mantua. a street. scene ii. friar lawrence‚Äôs cell. scene iii. a churchyard; in it a monument belonging to the capulets. dramatis person√¶ escalus, prince of veron\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "id": "QI-vJnOgsgq_",
        "outputId": "ab2a61b2-e2ed-49c5-b2a7-d380c40156fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(raw_text)"
      ],
      "metadata": {
        "id": "y6v9_KrPsjSe",
        "outputId": "7597b963-b951-48fc-8c4c-cf3ba7cae461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141092"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(raw_text)-window_size):\n",
        "    X = raw_text[i:i+window_size]\n",
        "    Y = raw_text[i+window_size]\n",
        "    dataX.append([char_to_idx[ch] for ch in X])\n",
        "    dataY.append(char_to_idx[Y])"
      ],
      "metadata": {
        "id": "9s11KpqSslln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dataX = np.array(dataX)\n",
        "dataY = np.array(dataY)"
      ],
      "metadata": {
        "id": "oTs59ZQ3qigr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataX.shape #n_sample, sqlen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcxAXbl1qubT",
        "outputId": "2b51d675-81d2-48a8-cfda-910b5bc86afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140992, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataY.shape"
      ],
      "metadata": {
        "id": "i-tarV2Hq7Ar",
        "outputId": "f09d23fd-e75e-43a4-d5b8-b3f7883e286f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140992,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "b6o8_rzgwQmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype = torch.long) #embedding\n",
        "        self.y = torch.tensor(y, dtype = torch.long) #cross entropy\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.X[idx], self.y[idx]\n",
        "        return sample"
      ],
      "metadata": {
        "id": "FWCLnTJArfi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextDataset(dataX, dataY)"
      ],
      "metadata": {
        "id": "k8aTN74avSKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "dataloader = DataLoader(train_dataset, batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "m_-3GWJJvh9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X_batch, y_batch in dataloader:\n",
        "    print(X_batch.shape)\n",
        "    print(y_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV9f-XI77EaP",
        "outputId": "bf210786-2923-491f-e9ec-eb048e22bd00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 100])\n",
            "torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, vocab_size, dropout_prob):\n",
        "        super(TextGenerator, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, input_size)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
        "        self.norm = nn.LayerNorm(hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, hn = self.lstm(x)\n",
        "        x = x[:, -1, :] # last cell of the last layer\n",
        "        x = self.norm(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2JMoVO_8v3Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 64\n",
        "hidden_size = 256\n",
        "num_layers = 3\n",
        "dropout_prob = 0.2\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = TextGenerator(input_size, hidden_size, num_layers, vocab_size, dropout_prob).to(device)"
      ],
      "metadata": {
        "id": "KV_eijCSyd6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_tensor = torch.randint(0, vocab_size, (1, 100)).to(device)\n",
        "output = model(dummy_tensor)\n",
        "print(output.argmax(dim = -1).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJa8rhFX0Uap",
        "outputId": "5073351c-5e4c-4416-ff24-899441423142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "lr = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "'''\n",
        "üîπ nn.CrossEntropyLoss y√™u c·∫ßu y_batch ph·∫£i l√† ki·ªÉu torch.long\n",
        "üîπ v√† y_pred ph·∫£i l√† torch.float\n",
        "N√≥ t·ª± th·ª±c hi·ªán softmax + log + ch·ªçn ƒë√∫ng index ‚Äî kh√¥ng c·∫ßn one-hot.\n",
        "CrossEntropyLoss c·∫ßn (batch,).\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Ftsc_1DQ0ik4",
        "outputId": "a88bdb98-c87c-42d1-89c6-4fe10f60b13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nüîπ nn.CrossEntropyLoss y√™u c·∫ßu y_batch ph·∫£i l√† ki·ªÉu torch.long\\nüîπ v√† y_pred ph·∫£i l√† torch.float\\nN√≥ t·ª± th·ª±c hi·ªán softmax + log + ch·ªçn ƒë√∫ng index ‚Äî kh√¥ng c·∫ßn one-hot.\\nCrossEntropyLoss c·∫ßn (batch,).\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    losses = 0\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        y_pred = model(X_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        losses += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    losses /= len(dataloader)\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {losses}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQhtNTGU1D1D",
        "outputId": "8fafaeff-1a6c-4951-cb86-22d39f2bb6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 1.9618118106778002\n",
            "Epoch 2/50, Loss: 1.5595216322724053\n",
            "Epoch 3/50, Loss: 1.4222104805783655\n",
            "Epoch 4/50, Loss: 1.324494192799293\n",
            "Epoch 5/50, Loss: 1.2417488836441628\n",
            "Epoch 6/50, Loss: 1.1614220718939379\n",
            "Epoch 7/50, Loss: 1.0849296617205044\n",
            "Epoch 8/50, Loss: 1.0080804107626207\n",
            "Epoch 9/50, Loss: 0.9293790420148853\n",
            "Epoch 10/50, Loss: 0.8544306745871009\n",
            "Epoch 11/50, Loss: 0.7821856476975007\n",
            "Epoch 12/50, Loss: 0.7132757025383778\n",
            "Epoch 13/50, Loss: 0.6480866976744899\n",
            "Epoch 14/50, Loss: 0.5911755326547121\n",
            "Epoch 15/50, Loss: 0.5425129911427922\n",
            "Epoch 16/50, Loss: 0.49816911495856925\n",
            "Epoch 17/50, Loss: 0.46224192025548966\n",
            "Epoch 18/50, Loss: 0.431004138964274\n",
            "Epoch 19/50, Loss: 0.39952911628569104\n",
            "Epoch 20/50, Loss: 0.37896235903789255\n",
            "Epoch 21/50, Loss: 0.3562955996816041\n",
            "Epoch 22/50, Loss: 0.3426946895957642\n",
            "Epoch 23/50, Loss: 0.32529385193181776\n",
            "Epoch 24/50, Loss: 0.31843800470232964\n",
            "Epoch 25/50, Loss: 0.2980880004281141\n",
            "Epoch 26/50, Loss: 0.29426870101592933\n",
            "Epoch 27/50, Loss: 0.2864420224866828\n",
            "Epoch 28/50, Loss: 0.2734488071958296\n",
            "Epoch 29/50, Loss: 0.26435749948754933\n",
            "Epoch 30/50, Loss: 0.2616710685355802\n",
            "Epoch 31/50, Loss: 0.2613774274971113\n",
            "Epoch 32/50, Loss: 0.24884056134957366\n",
            "Epoch 33/50, Loss: 0.24917169953079493\n",
            "Epoch 34/50, Loss: 0.24575375983941145\n",
            "Epoch 35/50, Loss: 0.23454848880424906\n",
            "Epoch 36/50, Loss: 0.24210099031482765\n",
            "Epoch 37/50, Loss: 0.2257020712209808\n",
            "Epoch 38/50, Loss: 0.22740651710388232\n",
            "Epoch 39/50, Loss: 0.226712279914187\n",
            "Epoch 40/50, Loss: 0.22202567316375388\n",
            "Epoch 41/50, Loss: 0.22431321100022528\n",
            "Epoch 42/50, Loss: 0.2194113209978855\n",
            "Epoch 43/50, Loss: 0.2139471164091529\n",
            "Epoch 44/50, Loss: 0.21801280025088526\n",
            "Epoch 45/50, Loss: 0.21496969424931842\n",
            "Epoch 46/50, Loss: 0.21064349257821613\n",
            "Epoch 47/50, Loss: 0.20698952057589853\n",
            "Epoch 48/50, Loss: 0.20553668070848213\n",
            "Epoch 49/50, Loss: 0.20061911856197834\n",
            "Epoch 50/50, Loss: 0.2094029302416393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "start = np.random.randint(0, len(raw_text)-seq_length)\n",
        "prompt = raw_text[start:start+seq_length]\n",
        "prompt = 'young men‚Äôs love then lies not truly in their hearts, but in their eyes'"
      ],
      "metadata": {
        "id": "zjnW4aaj8Gwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexed_prompt = [char_to_idx[ch] for ch in prompt]\n"
      ],
      "metadata": {
        "id": "Z1G299wO7hjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "print(f'Prompt: {prompt} \\n')\n",
        "with torch.no_grad():\n",
        "    for i in range(1000):\n",
        "        X = indexed_prompt\n",
        "        X = np.array(X)\n",
        "        X = np.expand_dims(X, axis = 0)\n",
        "        X = torch.tensor(X, dtype = torch.long).to(device)\n",
        "        pred = model(X)\n",
        "        index = pred.argmax(dim = -1).item()\n",
        "        next_char = idx_to_char[index]\n",
        "        print(next_char, end='')\n",
        "\n",
        "        indexed_prompt.append(index)\n",
        "        indexed_prompt = indexed_prompt[1:]\n",
        "print()\n",
        "print(\"DONE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwRsn2Ay8PZG",
        "outputId": "5ee90efa-e98b-4c15-8d1b-a3681cc2da49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: young men‚Äôs love then lies not truly in their hearts, but in their eyes \n",
            "\n",
            ", and but kill one life. i beg for juliet of an ill cook that cannot lick his fingers goes not with me. citiz‚Äôd than she will stay with thee, and not thy will and her beauty sighs from heaven clears, thy old groans you are well. [_exit._] scene ii. hall in capulet‚Äôs house. act ii chorus. scene i. an open place adjoining capulet‚Äôs garden. enter romeo. romeo. father, what news? what is the prince‚Äôs doom? friar lawrence. i am the greatest, able to bed, acting of the watch with lovers‚Äô brains, and then they do speak to tybalt, juliet pin‚Äôd to her heaven she said tybalt‚Äôs death, and then i have voulnt, and where me will i remain with worms that are thy chambermaids. o, here will i set up my everlasting rest; and shake the yoke of inauspicious stars that cannot lick his fingers goes not with me. citiz‚Äôd than she will stay with thee, and not thy will and her beauty sighs from heaven clears, thy old groans you are well. [_exit._] scene ii. hall in capulet‚Äôs house. act ii chorus. scene i. an op\n",
            "DONE\n"
          ]
        }
      ]
    }
  ]
}